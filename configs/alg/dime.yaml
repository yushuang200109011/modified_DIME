tau: 1.0
policy_tau: 1.0
utd: 2
gamma: 0.99
policy_delay: 3
batch_size: 512
buffer_size: 1000000
learning_starts: 50000
reset_models: False

ent_coef:
  type: "auto" # const or auto
  init: 1.0
  target: 6.0

critic:
  activation: 'relu'
  n_critics: 2
  hs: [1024, 1024]
  dropout_rate: null # None in yaml
  use_layer_norm: False
  n_atoms: 101
  v_min: -200
  v_max: 200
  entr_coeff: 0.005

optimizer:
  bn: True
  bn_momentum: 0.99
  bn_mode: brn_actor
  bn_warmup: 100000
  lr_critic: 3.0e-4
  lr_actor: 3.0e-4
  b1: 0.5
  do_actor_grad_clip: True
  actor_grad_clip: 1.0


actor:
  diff_steps: 16


